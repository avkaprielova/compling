{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F41f-X8Pqsjd",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLhaNCUkqmo8",
        "colab_type": "text"
      },
      "source": [
        "Use data from https://github.com/thedenaas/hse_seminars/tree/master/2018/seminar_13/data.zip\n",
        "Implement model in pytorch from \"An Unsupervised Neural Attention Model for Aspect Extraction, He et al, 2017\", also desribed in seminar notes.\n",
        "\n",
        "You can use sentence embeddings with attention **[7 points]**:\n",
        "\n",
        "$z_s = \\sum_{i}^n \\alpha_i e_{w_i}, z_s \\in R^d$ sentence embedding\n",
        "\n",
        "$\\alpha_i = softmax(d_i)$ attention weight for i-th token\n",
        "\n",
        "$d_i = e_{w_i}^T M y_s$ attention with trainable matrix $M \\in R^{dxd}$\n",
        "\n",
        "$y_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, y_s \\in R^d$ sentence context\n",
        "\n",
        "$e_{w_i} \\in R^d$, token embedding of size d\n",
        "\n",
        "$n$ - number of tokens in a sentence\n",
        "\n",
        "**Or** just use sentence embedding as an average over word embeddings **[5 points]**:\n",
        "\n",
        "$z_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, z_s \\in R^d$ sentence embedding\n",
        "\n",
        "$e_{w_i} \\in R^d$, token embedding of size d\n",
        "\n",
        "$n$ - number of tokens in a sentence\n",
        "\n",
        "$p_t = softmax(W z_s + b), p_t \\in R^K$ topic weights for sentence \n",
        "$s$, with trainable matrix $W \\in R^{dxK}$ and bias vector $b \\in R^K$\n",
        "\n",
        "$r_s = T^T p_t, r_s \\in R^d$ reconstructed sentence embedding as a weighted sum of topic embeddings\n",
        "\n",
        "$T \\in R^{Kxd}$ trainable matrix of topic embeddings, K=number of topics\n",
        "\n",
        "**Training objective:**$$ J = \\sum_{s \\in D} \\sum_{i=1}^n max(0, 1-r_s^T z_s + r_s^T n_i) + \\lambda ||T^T T - I ||^2_F  $$where\n",
        "$m$ random sentences are sampled as negative examples from dataset $D$ for each sentence $s$\n",
        "\n",
        "$n_i = \\frac 1 n \\sum_{i=j}^n e_{w_j}$ average of word embeddings in the i-th sentence\n",
        "\n",
        "$||T^T T - I ||_F$ regularizer, that enforces matrix $T$ to be orthogonal\n",
        "\n",
        "$||A||^2_F = \\sum_{i=1}^N\\sum_{j=1}^M a_{ij}^2, A \\in R^{NxM}$ Frobenius norm\n",
        "\n",
        "**[3 points]** Compute topic coherence for at least for 3 different number of topics. Use 10 nearest words for each topic. It means you have to train one model for each number of topics. You can use code from seminar notes with word2vec similarity scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_nFzlVbAVT0",
        "colab_type": "text"
      },
      "source": [
        "### Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGYGOCeSqjas",
        "colab_type": "code",
        "outputId": "249a70f3-e37d-4e2e-d7b8-7dee4cfa8297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "!wget https://github.com/thedenaas/hse_seminars/tree/master/2018/seminar_13/data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-22 18:13:12--  https://github.com/thedenaas/hse_seminars/tree/master/2018/seminar_13/data.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/thedenaas/hse_seminars/blob/master/2018/seminar_13/data.zip [following]\n",
            "--2020-03-22 18:13:17--  https://github.com/thedenaas/hse_seminars/blob/master/2018/seminar_13/data.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip                [ <=>                ]  64.25K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-03-22 18:13:17 (2.37 MB/s) - ‘data.zip’ saved [65794]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyY_kBEIqlbS",
        "colab_type": "code",
        "outputId": "6943fb24-3c3a-4ad4-d628-aa5c94633088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: data.txt                \n",
            "  inflating: stopwords.txt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVu7R8hsrc0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data.txt', 'r', encoding = 'utf-8') as f:\n",
        "    content = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5c2yLoDszYk",
        "colab_type": "code",
        "outputId": "7e08232d-42e3-481f-c9e8-76ce0092758d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(content), type(content)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4551, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-9Rr_EUs2t1",
        "colab_type": "code",
        "outputId": "462158c1-cc8a-4fe3-eca8-6da501a16a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "content[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Barclays' defiance of US fines has merit Barclays disgraced itself in many ways during the pre-financial crisis boom years. So it is tempting to think the bank, when asked by US Department of Justice to pay a large bill for polluting the financial system with mortgage junk between 2005 and 2007, should cough up, apologise and learn some humility. That is not the view of the chief executive, Jes Staley. Barclays thinks the DoJ’s claims are “disconnected from the facts” and that it has “an obligation to our shareholders, customers, clients and employees to defend ourselves against unreasonable allegations and demands.” The stance is possibly foolhardy, since going into open legal battle with the most powerful US prosecutor is risky, especially if you end up losing. But actually, some grudging respect for Staley and Barclays is in order. The US system for dishing out fines to errant banks for their mortgage sins has come to resemble a casino. The approach prefers settlements behind closed doors and the difference in size of penalties is never explained. Occasional leaks of the negotiating demands make the methodology appear even more arbitrary. Deutsche Bank was initially asked for $14bn (£11.5bn), but reached a settlement of $7.2bn on Thursday. Where is the rhyme or reason? There is also a strong suspicion that the roulette wheel is weighted against the Europeans. US banks, in the forms of JP Morgan, Goldman Sachs, Morgan Stanley, Bank of America and Citi, were at the front of the queue for settlement for no obvious reason. If Barclays created and distributed far fewer toxic mortgage securities than its US rivals, which is what the bank argues, why shouldn’t its fine be proportionately smaller? Neither Barclays nor the DoJ is talking hard numbers. But Barclays, it is said, was asked for $4bn, versus its own analysis that a fair sum would be $1bn and $2bn could have been swallowed for the sake of certainty. When the gap is so wide, Barclays is entitled to take its chances in court – and yes, it probably has an obligation to do so. A board can’t let $2bn slip out of the door just for the sake of a quiet life. The case will be messy, inevitably. Barclays’ practices were “plainly irresponsible and dishonest,” according to Loretta Lynch, the US attorney general. There is also a cache of ugly emails and documents. The DoJ lawsuit says Barclays employees called one parcel of securitised loans “craptacular”. Another was said to “look like shit”. However, that is almost par for the course in these cases. The central question is the right size of penalty. If Barclays thinks it has been singled out for unduly harsh treatment, the bank should try to prove its case. Staley will look like a fool if he fails, but the willingness to reject the easy option of settling is entirely legitimate.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8YpPOTM7cfk",
        "colab_type": "code",
        "outputId": "4eb87a9b-0559-44e5-82b0-b0100ca53af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "content[1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"How big is Hillary Clinton's lead in the presidential race? It depends on the poll Democratic candidate Hillary Clinton now has an 11-percentage-point lead over her Republican opponent Donald Trump, according to a poll released by PRRI and the Atlantic on Tuesday. If that weren’t already reason enough for Trump supporters to worry, a poll from NBC and the Wall Street Journal released on Monday put Clinton’s lead at 14 percentage points. But why the difference in numbers? If you want to follow polls in the 28 remaining days before the US votes, I strongly recommend you ignore the date that the poll was published – and focus instead on the dates that the poll was conducted. That PRRI/Atlantic poll was based on landline and cellphone interviews that took place on 5-9 October while the data for the NBC/WSJ poll was gathered on 8-9 October. Those dates are potentially significant given that on 8 October, a 2005 recording was released of Trump saying that, thanks to his fame, he was able to grab women “by the pussy”. It’s highly likely that a larger proportion of respondents were interviewed after the Trump recording was made public in the NBC/WSJ poll compared with the PRRI/Atlantic poll. That could mean a 14-percentage-point lead is a more accurate indication of Clinton’s current position in the race. But the crucial question is whether Clinton’s lead is temporary or permanent. We’ll need to keep an eye on numbers in the days ahead to understand that. In the meantime, though, it’s worth looking beyond the horserace numbers that appear at the top of the survey and digging a little further. In the PRRI/Atlantic poll, I was curious about a question that provided the statement: “These days society seems to punish men just for acting like men” – 36% of respondents agreed. Another 41% agreed with the statement: “Society as a whole has become too soft and feminine.” Those attitudes could provide useful information for understanding why voters might support their respective candidates.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6rny1BJtA6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('stopwords.txt', 'r', encoding = 'utf-8') as f:\n",
        "    stopwords = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H94VJLRdtCHh",
        "colab_type": "code",
        "outputId": "a2d6d325-f87f-42ec-83d4-881bac0a7de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(stopwords), type(stopwords)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(350, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqVZE74QAcSi",
        "colab_type": "text"
      },
      "source": [
        "### Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5E9BMfQt2OJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = set([x.strip() for x in stopwords])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvg6zUuStgSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYqhCoSItMek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [''] * len(content)\n",
        "for i, line in enumerate(content):\n",
        "    new_line = []\n",
        "    for t in line.split():\n",
        "        if t not in stopwords:\n",
        "            new_line.append(t)\n",
        "    new_line = ' '.join(new_line)\n",
        "    data[i] = new_line\n",
        "# to do:\n",
        "# 1. разбить на предложения\n",
        "# 2. для каждого предложения извлечь m случайных предложений как отрицательные примеры - попробовать 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbFyGV8CttkZ",
        "colab_type": "code",
        "outputId": "943dd076-4c37-43c2-8e5a-794a59844d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Barclays' defiance US fines merit Barclays disgraced ways pre-financial crisis boom years. So tempting think bank, asked US Department Justice pay large bill polluting financial system mortgage junk 2005 2007, cough up, apologise learn humility. That view chief executive, Jes Staley. Barclays thinks DoJ’s claims “disconnected facts” “an obligation shareholders, customers, clients employees defend against unreasonable allegations demands.” The stance possibly foolhardy, going open legal battle powerful US prosecutor risky, especially losing. But actually, grudging respect Staley Barclays order. The US system dishing fines errant banks mortgage sins resemble casino. The approach prefers settlements behind closed doors difference size penalties explained. Occasional leaks negotiating demands methodology appear arbitrary. Deutsche Bank initially asked $14bn (£11.5bn), reached settlement $7.2bn Thursday. Where rhyme reason? There strong suspicion roulette wheel weighted against Europeans. US banks, forms JP Morgan, Goldman Sachs, Morgan Stanley, Bank America Citi, front queue settlement obvious reason. If Barclays created distributed far fewer toxic mortgage securities US rivals, bank argues, shouldn’t fine proportionately smaller? Neither Barclays DoJ talking hard numbers. But Barclays, said, asked $4bn, versus analysis fair sum $1bn $2bn swallowed sake certainty. When gap wide, Barclays entitled take chances court – yes, probably obligation so. A board can’t $2bn slip door sake quiet life. The case messy, inevitably. Barclays’ practices “plainly irresponsible dishonest,” Loretta Lynch, US attorney general. There cache ugly emails documents. The DoJ lawsuit Barclays employees called parcel securitised loans “craptacular”. Another “look shit”. However, par course cases. The central question right size penalty. If Barclays thinks singled unduly harsh treatment, bank try prove case. Staley look fool fails, willingness reject easy option settling entirely legitimate.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkmK6ieUAj_n",
        "colab_type": "text"
      },
      "source": [
        "### Preparing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxl604E0uuhu",
        "colab_type": "code",
        "outputId": "bfbb8e6e-3f66-4ccb-b4f6-7d5f27fd953b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-22 18:22:59--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.144.237\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.144.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  86.9MB/s    in 18s     \n",
            "\n",
            "2020-03-22 18:23:17 (86.9 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCOzZV_0fkGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reconstruction_loss(r_s, z_s, n_i, T, lambda = 1):\n",
        "    # regularization_term = torch.norm(tt.matmul(tt.t(T), T) - lambda*tt.matrix_power(T, 0))\n",
        "    # reconstruction_loss = MarginRankingLoss\n",
        "    # return reconstruction_loss + regularization_term\n",
        "    return NotImplementedError\n",
        "    \n",
        "class ABAE(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(ABAE, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
        "        self.fc = nn.Linear(fc_num, hidden_dim)\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "    def forward(self, batch):\n",
        "        sentence, neg_sentences = batch\n",
        "        word_embeddings = self.embedding(sentence) # sequence of vectors\n",
        "        y_s = word_embeddings.mean(dim=0) # a single vector\n",
        "        p_t = self.softmax(self.fc(y_s)) # a single vector - shorter one\n",
        "        r_s = tt.matmul(tt.t(T), p_t)\n",
        "        loss = 0\n",
        "        for neg_sentence in neg_sentences:\n",
        "            n_i = self.embedding(neg_sentence).mean(dim=1)\n",
        "            loss += reconstruction_loss(r_s, z_s, n_i, T, lambda=1)\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMhyCGOq6LER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqvTMXDq6_OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _train_epoch(model, iterator, optimizer, curr_epoch):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = model(batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        curr_loss = loss.data.cpu().detach().item()\n",
        "        \n",
        "        loss_smoothing = i / (i+1)\n",
        "        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
        "\n",
        "        iterator.set_postfix(loss='%.5f' % running_loss)\n",
        "\n",
        "    return running_loss\n",
        "\n",
        "def _test_epoch(model, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    with tt.no_grad():\n",
        "        for batch in iterator:\n",
        "            loss = model(batch)\n",
        "            epoch_loss += loss.data.item()\n",
        "\n",
        "    return epoch_loss / n_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7EOCOv6AF2K",
        "colab_type": "text"
      },
      "source": [
        "### Topic Coherence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVIAsRr8AJNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmin, kmax = 4, 15\n",
        "\n",
        "topic_models = []\n",
        "for k in tqdm(range(kmin,kmax+1)):\n",
        "    model = TruncatedSVD(n_components=k) \n",
        "    W = model.fit_transform(A)\n",
        "    H = model.components_    \n",
        "    topic_models.append((k,W,H))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QeNoP39Az26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "\n",
        "w2v_model = gensim.models.Word2Vec.load(\"w2v-model.bin\")\n",
        "print(\"Model has %d terms\" % len(w2v_model.wv.vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBot2_1qA1Ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations\n",
        "\n",
        "\n",
        "def calculate_coherence(w2v_model, term_rankings):\n",
        "    overall_coherence = 0.0\n",
        "    for topic_index in range(len(term_rankings)):\n",
        "        # check each pair of terms\n",
        "        pair_scores = []\n",
        "        for pair in combinations(term_rankings[topic_index], 2):\n",
        "            pair_scores.append(w2v_model.similarity(pair[0], pair[1]))\n",
        "        # get the mean for all pairs in this topic\n",
        "        topic_score = sum(pair_scores) / len(pair_scores)\n",
        "        overall_coherence += topic_score\n",
        "    # get the mean score across all topics\n",
        "    return overall_coherence / len(term_rankings)\n",
        "\n",
        "\n",
        "k_values = []\n",
        "coherences = []\n",
        "for (k,W,H) in topic_models:\n",
        "    # Get all of the topic descriptors - the term_rankings, based on top 10 terms\n",
        "    term_rankings = []\n",
        "    for topic_index in range(k):\n",
        "        term_rankings.append(get_descriptor(terms, H, topic_index, 10))\n",
        "    # Now calculate the coherence based on our Word2vec model\n",
        "    k_values.append(k)\n",
        "    coherences.append(calculate_coherence(w2v_model, term_rankings))\n",
        "    print(\"K=%02d: Coherence=%.4f\" % (k, coherences[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqeH7SMFA6jZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(13,7))\n",
        "# create the line plot\n",
        "ax = plt.plot(k_values, coherences)\n",
        "plt.xticks(k_values)\n",
        "plt.xlabel(\"Number of Topics\")\n",
        "plt.ylabel(\"Mean Coherence\")\n",
        "# add the points\n",
        "plt.scatter( k_values, coherences, s=120)\n",
        "# find and annotate the maximum point on the plot\n",
        "ymax = max(coherences)\n",
        "xpos = coherences.index(ymax)\n",
        "best_k = k_values[xpos]\n",
        "plt.annotate( \"k=%d\" % best_k, xy=(best_k, ymax), xytext=(best_k, ymax), textcoords=\"offset points\", fontsize=16)\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObwntHHYBCLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = best_k\n",
        "# get the model that we generated earlier.\n",
        "W = topic_models[k-kmin][1]\n",
        "H = topic_models[k-kmin][2]\n",
        "\n",
        "for topic_index in range(k):\n",
        "    descriptor = get_descriptor(terms, H, topic_index, 10)\n",
        "    str_descriptor = \", \".join(descriptor)\n",
        "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}